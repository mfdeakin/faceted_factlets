---
title: "Optimization Tools"
date: 2023-07-07
draft: false
---

This page is just a short compilation of notes on tools for identifying and addressing performance bottlenecks.
Brendan Gregg has a more complete [listing][brgreggprof] of tools for profiling various parts of Linux systems; all of the tools listed here are aimed at understanding bottlenecks resulting from memory and CPU resource contention.
Furthermore, most of these tools will directly tell you if you're using cache-lines inefficiently or if your memory access patterns need to be improved; only imply it with cache-misses or memory bandwidth usage.
Cachegrind is the only tool I'm aware of which attempts to model cache-misses, however its cache model is based on older processors and probably not particularly reliable.
On the other hand, if your resource contention issues are on the CPU side of things, such as memory dependencies or inability to pipeline, some tools can help, such as llvm-mca.

[brgreggprof]: https://www.brendangregg.com/linuxperf.html

## optview2

A web view is available on compiler explorer.
This should probably be the first step after identifying an area that needs improvement if it's not clear what the problem is.
Alternatively, [optview2][optview2] can locally generate html associating results with specific lines of code from reports generated by llvm (no tools exist for gcc yet AFAIK).
This requires that you request reports on optimization attempts from llvm; you can generate these by adding the flag `-fsave-optimization-record` when compiling.
Most failed optimizations will be caused by potential side-effects which the compiler must keep track of; Ofek Shilon discusses several of these in his [talk][optview-talk].

[optview2]: https://github.com/OfekShilon/optview2
[optview-talk]: https://www.youtube.com/watch?v=qmEsx4MbKoc

## Profilers

There are 3 profiling tools used on Linux which I use; they are all based on hardware counters:

1. Perf
2. Intel VTune
3. Nvidia Visual Profiler (or nvvp)

In general I use perf when I'm doing a quick survey of CPU code or generating data for profile guided optimization and VTune when I want to determine what resource the code is held back by (generally either memory bandwidth or CPU instruction speed; or sometimes branch predictions).

For perf, the following generates `perf.data` which is suitable for profile guided optimization:

```bash
$ perf record -g -b ./executable {arguments}
```

I typically convert it to a call-graph, though they can quickly become unwieldy for non-trivial applications.
In those cases, microbenchmarks using your favorite microbenchmarking library ([Catch2][catch2], [Google Benchmark][gbench]) can be more useful for determining what the specific problem is.

```bash
$ perf report --call-graph
$ perf script | c++filt | gprof2dot -f perf | dot -Tpng -o callgraph.png
```

A popular way to visualize profiles is the [flame graph][flame]; a perl-free rust implementation is [available][flame-rs].
This produces a fixed width svg with layered stack-traces which makes analyzing hotspots in large programs much easier than with a call-graph.
To generate a flamegraph with the rust implementation, the following works:

```bash
$ PERF="perf" flamegraph -- ./executable {arguments}
```

NVVP is used for profiling and determining the bottlenecks of GPU kernels.

[catch2]: https://github.com/catchorg/Catch2
[gbench]: https://github.com/google/benchmark
[flame]: https://github.com/brendangregg/FlameGraph
[flame-rs]: https://github.com/jedbrown/flamegraph.git

## [llvm-mca][llvm-mca]

llvm-mca uses a processor model to estimate machine code efficiency (latency, througput, bottlenecks) and resource contention from the assembly rather than using actually running it with perf counter.
This enables it to provide more accurate information on what instructions are causing bottlenecks.
It has a particularly useful timeline view, which shows when instructions are ready to be scheduled, waiting to be scheduled, executing, and retiring.

However, because it's simulating the assembly and has it's own processor models with different resource names, it can be difficult to interpret without understanding the processor model it uses.
The processor models llvm-mca use can be found with some explanations in their main repos appropriately named `llvm/lib/Target/X86/*.td` file.

llvm-mca can be targeted on specific code in an assembly file, surround it with the comments `# LLVM-MCA-BEGIN` and `# LLVM-MCA-END`.
These can be added in C or C++ with `asm volatile("# LLVM_MCA_BEGIN":::"memory")` directives; though these can interfere with optimizations that would otherwise happen across these comments.

The comment can also contain identifying information after the `LLVM_MCA_BEGIN/END` marker.

[llvm-mca]: https://www.llvm.org/docs/CommandGuide/llvm-mca.html

## Profile Guided Optimization

First, generate a profile of the code with your favorite tool.

Second, convert it to a format your compiler can use. For gcc, this needs to be a gcov format, llvm has it's own format. llvm-profgen can be used to generate this:

```bash
$ llvm-profgen --perfdata=perf.data --binary=./executable --output=./perf.data.llvm
```

To generate gcc compatible data, add the `--format=gcc` option

Finally, rebuild the executable with the addition of the option to use profiling data. For gcc, add the flag `-fprofile-use=./perf.data.gcov`, for llvm, add the flag `-fprofile-sample-use=./perf.data.llvm`
